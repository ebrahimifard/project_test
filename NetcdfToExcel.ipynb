{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project name: NetCDF --> Excel\n",
    "#Description: It receives a NetCDF file with a predefined format (should we elaborate here?) and returns the equivalent file in excel format. \n",
    "#Programmers: Amir \\& Ashley\n",
    "#Date: 07-09-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task list\n",
    "## 1. Make the code more generic by not using the column names\n",
    "## 2. Annotating the columns in order to keep the column order\n",
    "## 3. Activate the 2-factor authentication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the packages\n",
    "#The openpyxl should also be installed (it is essential for saving the dataframe as an excel file) \n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the NetCDF file\n",
    "# ds_disk = xr.open_dataset(\"8-Plagioclase-trace-elements.nc\")\n",
    "#sheet names:\n",
    "#3-WR-Major-and-trace-elements\n",
    "#4-Amphibole-Major-elements\n",
    "#5-OPX-Major-elements\n",
    "#6-Glass-Major-elements\n",
    "#7-Plagioclase-Major-elements\n",
    "#8-Plagioclase-trace-elements\n",
    "\n",
    "sheet_name = \"3-WR-Major-and-trace-elements\"\n",
    "ds_disk = xr.open_dataset(sheet_name+\".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching the global attributes\n",
    "ds_global_attributes = ds_disk.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching the indexes (It will not be used later on as the indeces are also available in the variables)\n",
    "ds_indeces = list(ds_disk.coords.indexes[\"SAMPLE NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching the variables\n",
    "ds_disk_variables = ds_disk.to_dataframe().reset_index()\n",
    "#Fetching the column names\n",
    "column_names = list(ds_disk_variables.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the columns order\n",
    "orders = ds_disk_variables.iloc[len(ds_disk_variables)-1].to_dict()\n",
    "\n",
    "# Remove the columns order\n",
    "ds_disk_variables = ds_disk_variables.drop(axis=0, index=len(ds_disk_variables)-1)\n",
    "# ds_disk_variables = ds_disk_variables.drop(axis=0, index=len(ds_disk_variables))\n",
    "\n",
    "# Extraction of the order and place them in two arrays\n",
    "column_dict = {\"left\":{}, \"right\":{}}\n",
    "for i,j in orders.items():\n",
    "    info = str(j).split(\".\")\n",
    "    if j == \"flag\":\n",
    "        side, order = 1 , 0\n",
    "        column_dict[\"left\"][i] = \"1.0\"\n",
    "    else:\n",
    "        side, order = info[0] , info[1]\n",
    "        if side == \"1\":\n",
    "            column_dict[\"left\"][i] = j\n",
    "        elif side == \"2\":\n",
    "            column_dict[\"right\"][i] = j\n",
    "\n",
    "left_dict = {k: v for k, v in sorted(column_dict[\"left\"].items(), key=lambda item: item[1])}\n",
    "right_dict = {k: v for k, v in sorted(column_dict[\"right\"].items(), key=lambda item: item[1])}\n",
    "\n",
    "left = [i for i in left_dict]\n",
    "right = [i for i in right_dict]\n",
    "\n",
    "# Reordering the columns\n",
    "ds_disk_variables = ds_disk_variables[left+right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Reorganising the order of the columns\n",
    "# left = list(ds_disk_variables.columns)[:10]\n",
    "# right = list(ds_disk_variables.columns)[10:]\n",
    "# left = [\"SAMPLE NAME\", \"IGSN\", \"SPECIES\", \"sample preparation\", \"chemical treatment\", \"description\", \"grain spot ID\", \"spot location\", \"calculated average\", \"number of replicates\"]\n",
    "# ds_disk_variables = ds_disk_variables[left+right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an empty dictionary where the keys are the column names, and the values refer to the properties of those columns \n",
    "\n",
    "ds_dict = {i:[] for i in left+right}\n",
    "for j in left:\n",
    "    ds_dict[j] = {}\n",
    "    ds_dict[j][\"comment\"] = \"\"\n",
    "\n",
    "for j in right:\n",
    "    ds_dict[j] = {}\n",
    "    ds_dict[j][\"units\"] = \"\"\n",
    "    ds_dict[j][\"comment\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populating the dictionary \n",
    "for i in left:\n",
    "    if i == \"SAMPLE NAME\":\n",
    "        #Is this property already stored in the NetCDF file?\n",
    "        ds_dict[i][\"comment\"] = \"must match a sample on the SAMPLES tab column A\"\n",
    "    else:\n",
    "        ds_dict[i][\"comment\"] = ds_disk.data_vars[i].attrs[\"comment\"]\n",
    "\n",
    "        \n",
    "for j in right:\n",
    "    ds_dict[j][\"units\"] = ds_disk.data_vars[j].attrs[\"units\"]\n",
    "    ds_dict[j][\"comment\"] = ds_disk.data_vars[j].attrs[\"comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe for the left side of the tables's header\n",
    "s = pd.DataFrame(columns=ds_disk_variables.columns)\n",
    "s.loc[0] = [ds_dict[i][\"comment\"] if i in left else np.nan for i in s.columns] \n",
    "\n",
    "g = pd.DataFrame(columns=ds_disk_variables.columns)\n",
    "g.loc[0] = [i if i in left else np.nan for i in ds_disk_variables.columns]\n",
    "\n",
    "a1 = pd.concat([g,s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe for the right side of the tables's header\n",
    "\n",
    "h = pd.DataFrame(columns=ds_disk_variables.columns)\n",
    "h.loc[0] = [ds_dict[i][\"comment\"].replace(\"METHOD CODE: \",\"\") if i in right else np.nan for i in s.columns]\n",
    "h.loc[1] = [ds_dict[i][\"units\"] if i in right else np.nan for i in s.columns]\n",
    "\n",
    "v = pd.DataFrame(columns=ds_disk_variables.columns)\n",
    "v.loc[0] = [i if i in right else np.nan for i in ds_disk_variables.columns]\n",
    "\n",
    "a2 = pd.concat([v,h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual insertion of some values in the table (Do they exist in the NetCDF file? if so, where?)\n",
    "a2.iloc[0][\"number of replicates\"] = \"PARAMETER [list]\"\n",
    "a2.iloc[1][\"number of replicates\"] = \"METHOD CODE [more info]:\"\n",
    "a2.iloc[2][\"number of replicates\"] = \"UNIT [list]:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, the header to the table is created\n",
    "a3 = pd.concat([a2,a1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, the header and variables are added together\n",
    "a4 = pd.concat([a3,ds_disk_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the columns names\n",
    "k = [np.nan for i in range(len(left+right))]\n",
    "k[0] = ds_global_attributes[\"Description\"]\n",
    "\n",
    "a4.columns = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the dataframe index by the column \"SAMPLE NAME\"\n",
    "a4.index = a4[ds_global_attributes[\"Description\"]]\n",
    "\n",
    "#Removing the column \"SAMPLE NAME\" from the dataframe\n",
    "a4 = a4.drop(columns=[ds_global_attributes[\"Description\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the dataframe as an excel file\n",
    "a4.to_excel(sheet_name+\".xlsx\", sheet_name=ds_global_attributes[\"Title\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
